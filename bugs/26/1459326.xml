<?xml version="1.0" encoding="UTF-8" standalone="yes" ?>
<!DOCTYPE bugzilla SYSTEM "https://bugzilla.redhat.com/page.cgi?id=bugzilla.dtd">

<bugzilla version="4.4.12068.1"
          urlbase="https://bugzilla.redhat.com/"
          
          maintainer="bugzilla-error-list@redhat.com"
>

    <bug>
          <bug_id>1459326</bug_id>
          
          <creation_ts>2017-06-06 15:40:00 -0400</creation_ts>
          <short_desc>BUG: audit records being sent to the console even when auditd is running</short_desc>
          <delta_ts>2017-06-28 15:12:14 -0400</delta_ts>
          <reporter_accessible>1</reporter_accessible>
          <cclist_accessible>1</cclist_accessible>
          <classification_id>2</classification_id>
          <classification>Fedora</classification>
          <product>Fedora</product>
          <component>kernel</component>
          <version>26</version>
          <rep_platform>x86_64</rep_platform>
          <op_sys>Linux</op_sys>
          <bug_status>CLOSED</bug_status>
          <resolution>ERRATA</resolution>
          
          
          <bug_file_loc></bug_file_loc>
          <status_whiteboard></status_whiteboard>
          <keywords>Reopened</keywords>
          <priority>unspecified</priority>
          <bug_severity>low</bug_severity>
          <target_milestone>---</target_milestone>
          
          
          <everconfirmed>1</everconfirmed>
          <reporter name="Adam Williamson">awilliam</reporter>
          <assigned_to name="Paul Moore">pmoore</assigned_to>
          <cc>dhgutteridge</cc>
    
    
    <cc>dustymabe</cc>
    
    
    <cc>gansalmon</cc>
    
    
    <cc>iavaelooeyt</cc>
    
    
    <cc>ichavero</cc>
    
    
    <cc>itamar</cc>
    
    
    <cc>jonathan</cc>
    
    
    <cc>kernel-maint</cc>
    
    
    <cc>madhu.chinakonda</cc>
    
    
    <cc>mchehab</cc>
    
    
    <cc>pmoore</cc>
    
    
    <cc>rstrode</cc>
    
    
    <cc>sgrubb</cc>
          <qa_contact name="Fedora Extras Quality Assurance">extras-qa</qa_contact>
          
          <cf_fixed_in>kernel-4.11.6-101.fc24</cf_fixed_in>
          <cf_doc_type>If docs needed, set a value</cf_doc_type>
          <cf_release_notes></cf_release_notes>
          <cf_story_points>---</cf_story_points>
          
          <cf_environment></cf_environment>
          <cf_last_closed>2017-06-23 15:51:08</cf_last_closed>
          <cf_type>Bug</cf_type>
          <cf_regression_status>---</cf_regression_status>
          <cf_mount_type>---</cf_mount_type>
          <cf_documentation_action>---</cf_documentation_action>
          <cf_crm></cf_crm>
          <cf_verified_branch></cf_verified_branch>
          <cf_category>---</cf_category>
          <cf_ovirt_team>---</cf_ovirt_team>
          
          <cf_cloudforms_team>---</cf_cloudforms_team>
          
          
          
          
          <target_release>---</target_release>
          
          <votes>0</votes>

      

      

      

          <comment_sort_order>oldest_to_newest</comment_sort_order>  
          <long_desc isprivate="0" >
    <commentid>10482960</commentid>
    <comment_count>0</comment_count>
    <who name="Adam Williamson">awilliam</who>
    <bug_when>2017-06-06 15:40:39 -0400</bug_when>
    <thetext>Dusty and I are looking into why openQA&apos;s testing of the Atomic installer image shows a lot of audit logs being spewed to tty1 in some cases. One thing we&apos;ve found is quite interesting. It seems that if you boot without the &apos;quiet&apos; kernel arg on UEFI, audit logs get sent to tty1 - but the same is not true if you boot on BIOS. We&apos;re not sure why this is, but the inconsistency seemed odd to us, and worth reporting as a potential bug (not sure which behaviour is correct).</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10483017</commentid>
    <comment_count>1</comment_count>
    <who name="Adam Williamson">awilliam</who>
    <bug_when>2017-06-06 16:03:57 -0400</bug_when>
    <thetext>So I was a bit off in my initial description here: in fact it&apos;s not UEFI vs. BIOS, it&apos;s just some kind of race. Sometimes this happens, sometimes it doesn&apos;t.

For e.g., on production openQA, I see kernel message spammed to tty1 on the UEFI test for the last two days, but not for several days before that. On staging it happened to the *BIOS* test twice in the last few days, but not the UEFI test at all.

halfline also thinks there&apos;s something wrong with the default kernel log level. It seems that if you boot without &apos;quiet&apos; or &apos;debug&apos;, /proc/sys/kernel/printk shows:

7	4	1	7

i.e. the kernel log level is &apos;debug&apos;. halfline reckons the default level should be 4 (&apos;warning&apos;).</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10483186</commentid>
    <comment_count>2</comment_count>
    <who name="Adam Williamson">awilliam</who>
    <bug_when>2017-06-06 16:45:28 -0400</bug_when>
    <thetext>So the theory we&apos;ve developed here is that this happens when the getty is started before auditd starts running, and pjones suggested this change to resolve it:

&lt;pjones&gt; see if adding getty.target to auditd.service&apos;s Before= makes it go away
&lt;pjones&gt; that should at least cause them to get a) cleared when the getty grabs that tty, and b) not written to the tty after that
&lt;pjones&gt; if that theory is correct, anyway
&lt;dustymabe&gt; pjones: adamw - that works
&lt;dustymabe&gt; https://da.gd/GYt6 

so, re-assigning to audit for now.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10483338</commentid>
    <comment_count>3</comment_count>
    <who name="Steve Grubb">sgrubb</who>
    <bug_when>2017-06-06 17:32:40 -0400</bug_when>
    <thetext>The audit daemon does not use any TTY&apos;s. It closes its descriptors and reopens them to /dev/null. Are you sure this is not journald which enables auditing regardless of whether the user wants auditing or not? There&apos;s a whole lot of unhappy people on bug 1227379 wanting less audit events in their syslog. Maybe this is related?</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10483358</commentid>
    <comment_count>4</comment_count>
    <who name="Adam Williamson">awilliam</who>
    <bug_when>2017-06-06 17:39:09 -0400</bug_when>
    <thetext>It&apos;s not about the audit events *happening*, it&apos;s about them being printed to tty1, which seems undesirable.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10483383</commentid>
    <comment_count>5</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-06 17:48:55 -0400</bug_when>
    <thetext>so this looks like a race condition that *can* be solved by putting `Before=getty.target` into auditd.service. Not saying that is the solution to this BZ, but that is one way to *fix* it on a system that is showing the problem.

It is worth noting that a system that is showing this problem is not receiving the messages from the kernel&apos;s audit.c. I straced auditd on a running system and I see this:

```
[root@localhost ~]# strace -F -s 512 -p 723 2&gt;&amp;1 | tee straceout.txt 
strace: Process 723 attached with 2 threads
[pid   723] epoll_wait(6,  &lt;unfinished ...&gt;
[pid   724] futex(0x55fe3d049288, FUTEX_WAIT_PRIVATE, 0, NULL &lt;unfinished ...&gt;
[pid   723] &lt;... epoll_wait resumed&gt; [], 64, 59743) = 0
[pid   723] epoll_wait(6,

```

all the while messages audit messages are printing to tty1

I looked at auditd&apos;s fds and this is what I see:

```
[root@localhost ~]# lsof -p 723
COMMAND PID USER   FD      TYPE             DEVICE SIZE/OFF  NODE NAME
auditd  723 root  cwd       DIR              253,0     4096    70 /
auditd  723 root  rtd       DIR              253,0     4096    70 /
auditd  723 root  txt       REG              253,0   120248  2087 /usr/sbin/auditd
auditd  723 root  mem       REG              253,0    56784  1814 /usr/lib64/libnss_files-2.25.so
auditd  723 root  mem       REG              253,0    36512  1819 /usr/lib64/libnss_sss.so.2
auditd  723 root  mem       REG              253,0   467600  1854 /usr/lib64/libpcre.so.1.2.8
auditd  723 root  mem       REG              253,0   158320  1929 /usr/lib64/libselinux.so.1
auditd  723 root  mem       REG              253,0   109800  1907 /usr/lib64/libresolv-2.25.so
auditd  723 root  mem       REG              253,0    15288  1691 /usr/lib64/libkeyutils.so.1.6
auditd  723 root  mem       REG              253,0    19496  1534 /usr/lib64/libdl-2.25.so
auditd  723 root  mem       REG              253,0    61680  1699 /usr/lib64/libkrb5support.so.0.1
auditd  723 root  mem       REG              253,0    15344  1499 /usr/lib64/libcom_err.so.2.1
auditd  723 root  mem       REG              253,0   209904  1687 /usr/lib64/libk5crypto.so.3.1
auditd  723 root  mem       REG              253,0  2163088  1484 /usr/lib64/libc-2.25.so
auditd  723 root  mem       REG              253,0   958040  1697 /usr/lib64/libkrb5.so.3.3
auditd  723 root  mem       REG              253,0   316928  1636 /usr/lib64/libgssapi_krb5.so.2.2
auditd  723 root  mem       REG              253,0  1226376  1741 /usr/lib64/libm-2.25.so
auditd  723 root  mem       REG              253,0    43656  1921 /usr/lib64/librt-2.25.so
auditd  723 root  mem       REG              253,0   149800  1883 /usr/lib64/libpthread-2.25.so
auditd  723 root  mem       REG              253,0    19352  1487 /usr/lib64/libcap-ng.so.0.0.0
auditd  723 root  mem       REG              253,0   122080  1454 /usr/lib64/libaudit.so.1.0.0
auditd  723 root  mem       REG              253,0   123184  1456 /usr/lib64/libauparse.so.0.0.0
auditd  723 root  mem       REG              253,0   115472  1807 /usr/lib64/libnsl-2.25.so
auditd  723 root  mem       REG              253,0    42560  2040 /usr/lib64/libwrap.so.0.7.6
auditd  723 root  mem       REG              253,0   187368  1423 /usr/lib64/ld-2.25.so
auditd  723 root    0u      CHR                1,3      0t0  1028 /dev/null
auditd  723 root    1u      CHR                1,3      0t0  1028 /dev/null
auditd  723 root    2u      CHR                1,3      0t0  1028 /dev/null
auditd  723 root    3u  netlink                         0t0 17852 AUDIT
auditd  723 root    5w      REG              253,0      199 31448 /var/log/audit/audit.log
auditd  723 root    6u  a_inode               0,12        0  9775 [eventpoll]
auditd  723 root    7u  a_inode               0,12        0  9775 [eventfd]
auditd  723 root    8u     unix 0xffff92a8f9857000      0t0 17856 type=DGRAM
auditd  723 root    9u     unix 0xffff92a8f9855800      0t0 17865 type=STREAM
auditd  723 root   10u     unix 0xffff92a8f9856c00      0t0 17866 type=STREAM
[root@localhost ~]# 
[root@localhost ~]# 
[root@localhost ~]# ls -l /proc/723/fd/ 
total 0
lrwx------. 1 root root 64 Jun  6 17:12 0 -&gt; /dev/null
lrwx------. 1 root root 64 Jun  6 17:12 1 -&gt; /dev/null
lrwx------. 1 root root 64 Jun  6 17:12 10 -&gt; socket:[17866]
lrwx------. 1 root root 64 Jun  6 17:12 2 -&gt; /dev/null
lrwx------. 1 root root 64 Jun  6 17:12 3 -&gt; socket:[17852]
l-wx------. 1 root root 64 Jun  6 17:12 5 -&gt; /var/log/audit/audit.log
lrwx------. 1 root root 64 Jun  6 17:12 6 -&gt; anon_inode:[eventpoll]
lrwx------. 1 root root 64 Jun  6 17:12 7 -&gt; anon_inode:[eventfd]
lrwx------. 1 root root 64 Jun  6 17:12 8 -&gt; socket:[17856]
lrwx------. 1 root root 64 Jun  6 17:12 9 -&gt; socket:[17865]
``` 


I tried to start auditd at system start with strace enabled but that did not yield a system that showed the problem, so the race condition was not observed and the strace output is probably not useful. Peter Jones will have some other notes/comments to add most likely.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10483412</commentid>
    <comment_count>6</comment_count>
    <who name="Steve Grubb">sgrubb</who>
    <bug_when>2017-06-06 18:05:47 -0400</bug_when>
    <thetext>During boot systemd is sending an event for each service that starts up. This is required for common criteria. The problem is that journald enables auditing and connects to a netlink multicast socket for the audit system and starts collecting audit events. This can&apos;t be turned off by configuration. I think these events gets passed to rsyslog which then puts it on the screen. This is most likely what you are seeing. I have no idea how the audit daemon could write to TTY1.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10483446</commentid>
    <comment_count>7</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-06 18:30:24 -0400</bug_when>
    <thetext>
the system boots up with console=tty1 so the kernel messages are coming to tty1. my understanding is that once auditd is started the audit kernel messages shouldn&apos;t come to the console of the machine. If the message doesn&apos;t make it to the audit daemon then i think it defaults back to printing via printk

https://github.com/vathpela/linux/blob/master/kernel/audit.c#L500

peter jones has much more context on this topic. This is way below my level of knowledge :)</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10483631</commentid>
    <comment_count>8</comment_count>
    <who name="Steve Grubb">sgrubb</who>
    <bug_when>2017-06-06 20:47:10 -0400</bug_when>
    <thetext>OK. Then this is about the kernel doing printk and not anything to do with the audit daemon? If audit is not enabled (audit=1 on kernel boot command line and auditd has not started), there is not supposed to be any events except AVC&apos;s. So, this may be a case where systemd/journal is enabling audit on its own. One way to check this is to uninstall the audit daemon and then see if you still get events during boot. If you get even just 1 event, this bz should be transferred to systemd.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10483816</commentid>
    <comment_count>9</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-06 22:35:04 -0400</bug_when>
    <thetext>
so you are saying that if audit isn&apos;t started then i should never see an audit message other than an avc?

in our case auditd is started and running, but we think it is not properly receiving messages from the kernel, so it falls back to printk. 

I guess we&apos;ll try to debug this more tomorrow. Thanks for the discussion so far.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10485334</commentid>
    <comment_count>10</comment_count>
    <who name="Steve Grubb">sgrubb</who>
    <bug_when>2017-06-07 08:37:46 -0400</bug_when>
    <thetext>That is correct. When auditd starts, it sends an audit enable command to the kernel to start the flow of events. If you did not boot with audit=1, then you should see no events. Rather than uninstall it, you can &quot;systemctl disable auditd&quot;.

Auditd appears to be working fine. Looking at the data collected in comment 5, I see stding, stdout, and stderr all pointing /dev/null. And auditd is properly receiving events on descriptor 3 which is the netlink socket.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10485423</commentid>
    <comment_count>11</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-07 08:58:26 -0400</bug_when>
    <thetext>hey steve, is it possible for you to join us on IRC? There are several of us in #fedora-desktop on gimpnet https://wiki.gnome.org/Sysadmin/IRC

alternatively you can propose a different channel for us to join.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10485554</commentid>
    <comment_count>12</comment_count>
    <who name="Ray Strode [halfline]">rstrode</who>
    <bug_when>2017-06-07 09:38:25 -0400</bug_when>
    <thetext>so my reading of the link in comment 7 says the messages get unconditionaly printk as a notice. See this code:

	/* at this point it is uncertain if we will ever send this to auditd so
	 * try to send the message via printk before we go any further */
        kauditd_printk_skb(skb);

That suggests there isn&apos;t some fall back if auditd is unavailable.

So this is really about the console log level, I guess.  The messages are printed at level 5.  The kernel log level starts at 7 when quiet is removed. That means the audit messages should always go to the console if there&apos;s no quiet on the kernel command line, unless i&apos;m missing something.  If the messages sometimes don&apos;t show up, I guess that means something is doing the equivalent of dmesg -n4 or the equivalent of dmesg -D before the messages are printed (or something).  in the cases when the messages do show up something isn&apos;t doing that, I guess. maybe that&apos;s the race?

Note there isn&apos;t just audit messages in the output, if you look at

https://openqa.fedoraproject.org/tests/106013#step/_console_wait_login/8

There&apos;s also &quot;random: crng done&quot;.  Would be interesting to see how f25 behaves.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10485603</commentid>
    <comment_count>13</comment_count>
    <who name="Ray Strode [halfline]">rstrode</who>
    <bug_when>2017-06-07 09:48:56 -0400</bug_when>
    <thetext>
(In reply to Ray Strode [halfline] from comment #12)
&gt; so my reading of the link in comment 7 says the messages get unconditionaly
&gt; printk as a notice. See this code:
&gt; 
&gt; 	/* at this point it is uncertain if we will ever send this to auditd so
&gt; 	 * try to send the message via printk before we go any further */
&gt;         kauditd_printk_skb(skb);
&gt; 
&gt; That suggests there isn&apos;t some fall back if auditd is unavailable.
So I was wrong.  that code is called from kaudit_hold_skb which only gets called in error conditions.

So this could indeed be an auditd bug or selinux preventing auditd from getting audit messages or something like that.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486093</commentid>
    <comment_count>14</comment_count>
    <who name="Ray Strode [halfline]">rstrode</who>
    <bug_when>2017-06-07 11:34:22 -0400</bug_when>
    <thetext>I don&apos;t think this is an auditd bug.  dustymabe did some gdb debugging:

&lt;dustymabe&gt; (gdb) call (struct epoll_event *) malloc(sizeof(struct epoll_event))
&lt;dustymabe&gt; $1 = (struct epoll_event *) 0x7f1a2504dc20
&lt;dustymabe&gt; (gdb) call epoll_ctl(6, 1, 3, $1)
&lt;dustymabe&gt; $2 = -1
&lt;dustymabe&gt; (gdb)  p errno
&lt;dustymabe&gt; $3 = 17

so the netlink socket (fd 6) is already in the epoll set and and auditd is waiting in epoll_wait. it&apos;s not getting woken up by the kernel though.

kernel probably forgot about it.

sgrubb thinks the bug may have been introduced by this commit:

https://www.redhat.com/archives/linux-audit/2017-March/msg00114.html</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486117</commentid>
    <comment_count>15</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-07 11:41:16 -0400</bug_when>
    <thetext>Two questions:

* What kernel version?

* Does restarting auditd quiet the records to the console?</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486124</commentid>
    <comment_count>16</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-07 11:43:56 -0400</bug_when>
    <thetext>(In reply to Ray Strode [halfline] from comment #14)
&gt; sgrubb thinks the bug may have been introduced by this commit:
&gt; 
&gt; https://www.redhat.com/archives/linux-audit/2017-March/msg00114.html

There were a number of big changes to the kernel&apos;s audit daemon tracking code to fix a lot of really bad, and long standing problems; I wouldn&apos;t attribute it to that single patch just yet.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486141</commentid>
    <comment_count>17</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-07 11:48:17 -0400</bug_when>
    <thetext>(In reply to Paul Moore from comment #15)
&gt; Two questions:
&gt; 
&gt; * What kernel version?

kernel-4.11.0-2.fc26.x86_64

&gt; 
&gt; * Does restarting auditd quiet the records to the console?

[fedora@cloudhost ~]$ sudo systemctl restart auditd 
Failed to restart auditd.service: Operation refused, unit auditd.service may be requested by dependency only (it is configured to refuse manual start/stop).
See system logs and &apos;systemctl status auditd.service&apos; for details.

??</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486163</commentid>
    <comment_count>18</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-07 11:53:05 -0400</bug_when>
    <thetext>(In reply to Dusty Mabe from comment #17)
&gt; (In reply to Paul Moore from comment #15)
&gt; &gt; Two questions:
&gt; &gt; 
&gt; &gt; * What kernel version?
&gt; 
&gt; kernel-4.11.0-2.fc26.x86_64

I&apos;m guessing that is missing the commit below; it needed to be backported by hand and resubmitted to stable (https://www.redhat.com/archives/linux-audit/2017-May/msg00068.html).

  commit 48d0e023af9799cd7220335baf8e3ba61eeafbeb
  Author: Paul Moore &lt;paul@paul-moore.com&gt;
  Date:   Tue May 2 10:16:05 2017 -0400                                           
                                                                                
    audit: fix the RCU locking for the auditd_connection structure              
                                                                                
    Cong Wang correctly pointed out that the RCU read locking of the            
    auditd_connection struct was wrong, this patch correct this by              
    adopting a more traditional, and correct RCU locking model.                 
                                                                                
    This patch is heavily based on an earlier prototype by Cong Wang.           
                                                                                
    Cc: &lt;stable@vger.kernel.org&gt; # 4.11.x-                                      
    Reported-by: Cong Wang &lt;xiyou.wangcong@gmail.com&gt;                           
    Signed-off-by: Cong Wang &lt;xiyou.wangcong@gmail.com&gt;                         
    Signed-off-by: Paul Moore &lt;paul@paul-moore.com&gt; 

Are you able to reproduce this enough such that if I built a scratch kernel for testing you would be able to verify it?

&gt; &gt; * Does restarting auditd quiet the records to the console?
&gt; 
&gt; [fedora@cloudhost ~]$ sudo systemctl restart auditd 
&gt; Failed to restart auditd.service: Operation refused, unit auditd.service may
&gt; be requested by dependency only (it is configured to refuse manual
&gt; start/stop).
&gt; See system logs and &apos;systemctl status auditd.service&apos; for details.

The auditd systemd unit file can be very cranky, you probably need to just kill auditd and restart it.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486172</commentid>
    <comment_count>19</comment_count>
    <who name="Steve Grubb">sgrubb</who>
    <bug_when>2017-06-07 11:54:51 -0400</bug_when>
    <thetext>Correction, I didn&apos;t say
https://www.redhat.com/archives/linux-audit/2017-March/msg00114.html
caused the problem, I said maybe it fixes the problem. :-)

To restart the audit daemon, use the service command.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486190</commentid>
    <comment_count>20</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-07 11:59:09 -0400</bug_when>
    <thetext>(In reply to Paul Moore from comment #18)

&gt; 
&gt; Are you able to reproduce this enough such that if I built a scratch kernel
&gt; for testing you would be able to verify it?
&gt; 

It&apos;s doesn&apos;t happen every time but seems to be reliable enough that I can get it to happen by just rebooting a box &lt; 5 times. Scratch build might be useful.

&gt; 
&gt; The auditd systemd unit file can be very cranky, you probably need to just
&gt; kill auditd and restart it.

killed auditd and restarted it - cleared up the problem, no more messages coming to the console.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486227</commentid>
    <comment_count>21</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-07 12:03:56 -0400</bug_when>
    <thetext>(In reply to Dusty Mabe from comment #20)
&gt; (In reply to Paul Moore from comment #18)
&gt; &gt; Are you able to reproduce this enough such that if I built a scratch kernel
&gt; &gt; for testing you would be able to verify it?
&gt; 
&gt; It&apos;s doesn&apos;t happen every time but seems to be reliable enough that I can
&gt; get it to happen by just rebooting a box &lt; 5 times. Scratch build might be
&gt; useful.

FWIW, I&apos;ve been restarting my Rawhide test system with my test kernels (v4.12 based) while we&apos;ve been discussing this BZ and I haven&apos;t seen the problem.

I&apos;ll do a 4.11 stable kernel build right now, but if you are feeling adventurous you can try the latest build from here:

* https://copr.fedorainfracloud.org/coprs/pcmoore/kernel-secnext
 
&gt; &gt; The auditd systemd unit file can be very cranky, you probably need to just
&gt; &gt; kill auditd and restart it.
&gt; 
&gt; killed auditd and restarted it - cleared up the problem, no more messages
&gt; coming to the console.

Okay, that sorta confirms what I&apos;m thinking; the kernel is somehow missing the auditd registration.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486742</commentid>
    <comment_count>22</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-07 14:29:51 -0400</bug_when>
    <thetext>(In reply to Paul Moore from comment #21)

&gt; I&apos;ll do a 4.11 stable kernel build right now, 

Let me know when you have a link to that and i&apos;ll try it out.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10486901</commentid>
    <comment_count>23</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-07 14:46:22 -0400</bug_when>
    <thetext>Sorry for the delay, I got a bit distracted, but here is the build:

* https://koji.fedoraproject.org/koji/taskinfo?taskID=19902321

It&apos;s the standard Fedora kernel-4.11.4-300.fc26.src.rpm kernel with the fix mentioned above in comment #18.  Let me know if it works, or doesn&apos;t, for you.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10487660</commentid>
    <comment_count>24</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-07 21:08:20 -0400</bug_when>
    <thetext>I first tried to reproduce with the latest kernel in updates-testing:

kernel-core-4.11.3-302.fc26.x86_64

I *was* able to reproduce with this kernel. I then tried with the kernel from your scratch build:

kernel-core-4.11.4-300.1.testing.fc26.x86_64

With initial testing I have not been able to reproduce this. I&apos;ll give it some more tries, but preliminary results look like the issue is fixed with your scratch build.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10487664</commentid>
    <comment_count>25</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-07 21:13:21 -0400</bug_when>
    <thetext>sigh, spoke just a little too soon. I got it to reproduce at least once with the scratch build kernel :(</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10490035</commentid>
    <comment_count>26</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-08 11:30:41 -0400</bug_when>
    <thetext>I was stuck in meetings this morning so I didn&apos;t get to make any progress on this, but I&apos;m building a dev kernel right now to play with, I&apos;ll update the BZ when I&apos;ve got something to report.

In the meantime, if you wanted to give the 4.12-rcX kernels a shot that might be an interesting data point, but it isn&apos;t a requirement.

* https://copr.fedorainfracloud.org/coprs/pcmoore/kernel-secnext</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10490381</commentid>
    <comment_count>27</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-08 13:40:58 -0400</bug_when>
    <thetext>Quick update: after rebooting my test machine using a locally built kernel based on kernel-4.11.4-300.fc26 with the RCU fix applied I was finally able to see the problem ... on the 15th reboot :/

To add a bit more information, the kernel definitely doesn&apos;t think auditd is connected:

  # rpm -q audit
  audit-2.7.6-1.fc27.x86_64
  # uname -r
  4.11.4+
  # auditctl -s
  enabled 1
  failure 1
  pid 0
  rate_limit 0
  backlog_limit 64
  lost 0
  backlog 0
  backlog_wait_time 60000
  loginuid_immutable 0 unlocked</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10490383</commentid>
    <comment_count>28</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-08 13:42:05 -0400</bug_when>
    <thetext>(In reply to Paul Moore from comment #27)
&gt; Quick update: after rebooting my test machine using a locally built kernel
&gt; based on kernel-4.11.4-300.fc26 with the RCU fix applied I was finally able
&gt; to see the problem ... on the 15th reboot :/
&gt; 
&gt; To add a bit more information, the kernel definitely doesn&apos;t think auditd is
&gt; connected:
&gt; 
&gt;   # rpm -q audit
&gt;   audit-2.7.6-1.fc27.x86_64
&gt;   # uname -r
&gt;   4.11.4+
&gt;   # auditctl -s
&gt;   enabled 1
&gt;   failure 1
&gt;   pid 0
&gt;   rate_limit 0
&gt;   backlog_limit 64
&gt;   lost 0
&gt;   backlog 0
&gt;   backlog_wait_time 60000
&gt;   loginuid_immutable 0 unlocked

Additional:

  # pidof auditd
  358</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10490492</commentid>
    <comment_count>29</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-08 14:22:39 -0400</bug_when>
    <thetext>I added some additional instrumentation to try and determine the root cause, but after 30 reboots I had not triggered the problem again.  I added a small bit of scripting to rc.local and which should keep automatically rebooting the system until the problem is triggered, hopefully this will help ...</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10490648</commentid>
    <comment_count>30</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-08 15:22:50 -0400</bug_when>
    <thetext>After almost on hour of continuous reboots I&apos;m still not seeing the problem, clearly the solution is to introduce extra instrumentation ;)

Time to look a bit closer.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10491104</commentid>
    <comment_count>31</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-08 19:35:43 -0400</bug_when>
    <thetext>Last update for today: I backed off on the instrumentation and was able to reproduce the problem, some notes:

* I only see one AUDIT_SET/AUDIT_STATUS_PID message to set register the running auditd instance, I&apos;m not seeing any indication that auditd is unregistering itself.

* I need to remove the audit printk rate limiter as that is causing messages to be dropped in this case, but I&apos;m not seeing the AUDIT_CONFIG_CHANGE record one would expect from an auditd registration.

I&apos;m going to continue testing, but my current theory is that there is some odd situation where the kauditd_thread attempts to send queued records up to auditd before everything is &quot;OK&quot; with registration, fails, and resets the connection (as it should on failure).

More updates when I know more ...</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10493132</commentid>
    <comment_count>32</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-09 10:01:51 -0400</bug_when>
    <thetext>Never really paid any attention to this before, but I think I notice this same problem on my Fedora 25 desktop at home. I switched to a different tty (to get to a login prompt) and I notice audit messages there. auditd is running.

This might be an interesting data point.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10493532</commentid>
    <comment_count>33</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-09 11:54:51 -0400</bug_when>
    <thetext>(In reply to Dusty Mabe from comment #32)
&gt; Never really paid any attention to this before, but I think I notice this
&gt; same problem on my Fedora 25 desktop at home. I switched to a different tty
&gt; (to get to a login prompt) and I notice audit messages there. auditd is
&gt; running.
&gt; 
&gt; This might be an interesting data point.

Possibly, but I&apos;m not sure how helpful it will be at this point; there have been a *lot* of changes upstream.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10493676</commentid>
    <comment_count>34</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-09 13:01:47 -0400</bug_when>
    <thetext>One quick update: defeating the audit printk rate limit would appear to make the problem disappear on my test system.  Considering that only kauditd_thread should be the only one calling into that function here it tends to lend credibility to the theory in comment #31.

Resuming testing with the rate limiter restored and some instrumentation in auditd_reset().</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10493842</commentid>
    <comment_count>35</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-09 14:27:47 -0400</bug_when>
    <thetext>I need to preface this by saying that I don&apos;t have any confirmation that this is indeed the problem, however, looking at the code I think I may have found the problem ...

This issue is partly due to the read-copy nature of RCU, and partly due to how we sync the auditd_connection state across kauditd_thread and the audit control channel.  The kauditd_thread thread is always running so it can service the record queues and emit the multicast messages, if it happens to be just past the &quot;main_queue&quot; label, but before the &quot;if (sk == NULL || ...)&quot; if-statement which calls auditd_reset() when the new auditd connection is registered it could end up resetting the auditd connection, regardless of if it is valid or not.  This is a rather small window and the variable nature of multi-core scheduling explains why this is proving rather difficult to reproduce.

I just had this thought, so I haven&apos;t fully fleshed out the possible solutions, but possible solutions include one, or more, of the following:

* Don&apos;t call auditd_reset() from kauditd_thread if the local copy of the connection state is disconnected

* Pass an optional auditd_connection pointer to auditd_reset() and only do the reset if the pointer is current

* Other/TBD

I&apos;ll follow up with patches/test-builds once I have a reasonable solution (the above may or may not be it).</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10499169</commentid>
    <comment_count>36</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-12 17:16:34 -0400</bug_when>
    <thetext>Today&apos;s update: I believe I have a fix, my dev kernel has been running for a few hours now in a rapid reboot cycle and I&apos;ve yet to trigger the problem.  I&apos;ll attach the current patch in a moment, but here is a COPR build (currently building) for a F26 kernel with the patch:

* https://copr.fedorainfracloud.org/coprs/build/564483</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10499171</commentid>
    <comment_count>37</comment_count>
      <attachid>1287102</attachid>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-12 17:17:41 -0400</bug_when>
    <thetext>Created attachment 1287102
01-XXX-audit-reset_fix.patch</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10499177</commentid>
    <comment_count>38</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-12 17:21:58 -0400</bug_when>
    <thetext>Nevermind, scratch all that about today&apos;s update ... while attaching the patch I noticed a small problem with auditd unregistering itself.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10502593</commentid>
    <comment_count>39</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-13 15:22:13 -0400</bug_when>
    <thetext>Today&apos;s update: Let&apos;s try this again.  I&apos;ve updated the patch and the test kernel has been chugging away for several hours now with no sign of the problem.  Dusty, any chance you could try the kernel below to see if it solves the problem on your system?

* https://copr.fedorainfracloud.org/coprs/pcmoore/kernel-testing/build/564499</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10502596</commentid>
    <comment_count>40</comment_count>
      <attachid>1287438</attachid>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-13 15:23:04 -0400</bug_when>
    <thetext>Created attachment 1287438
04-XXX-audit-reset_fix.patch</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10513640</commentid>
    <comment_count>41</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-16 11:57:06 -0400</bug_when>
    <thetext>I merged the following patch upstream and will be sending it to Linus during the next merge window (it doesn&apos;t seem significant enough to warrant a -stable backport upstream):

  commit c81be52a3ac0267aa830a2c4cb769030ea3483c9
  Author: Paul Moore &lt;paul@paul-moore.com&gt;
  Date:   Mon Jun 12 09:35:24 2017 -0400

    audit: fix a race condition with the auditd tracking code
    
    Originally reported by Adam and Dusty, it appears we have a small
    race window in kauditd_thread(), as documented in the Fedora BZ:
    
     * https://bugzilla.redhat.com/show_bug.cgi?id=1459326#c35
    
     &quot;This issue is partly due to the read-copy nature of RCU, and
      partly due to how we sync the auditd_connection state across
      kauditd_thread and the audit control channel.  The kauditd_thread
      thread is always running so it can service the record queues and
      emit the multicast messages, if it happens to be just past the
      &quot;main_queue&quot; label, but before the &quot;if (sk == NULL || ...)&quot;
      if-statement which calls auditd_reset() when the new auditd
      connection is registered it could end up resetting the auditd
      connection, regardless of if it is valid or not.  This is a rather
      small window and the variable nature of multi-core scheduling
      explains why this is proving rather difficult to reproduce.&quot;
    
    The fix is to have functions only call auditd_reset() when they
    believe that the kernel/auditd connection is still valid, e.g.
    non-NULL, and to have these callers pass their local copy of the
    auditd_connection pointer to auditd_reset() where it can be compared
    with the current connection state before resetting.  If the caller
    has a stale state tracking pointer then the reset is ignored.
    
    We also make a small change to kauditd_thread() so that if the
    kernel/auditd connection is dead we skip the retry queue and send the
    records straight to the hold queue.  This is necessary as we used to
    rely on auditd_reset() to occasionally purge the retry queue but we
    are going to be calling the reset function much less now and we want
    to make sure the retry queue doesn&apos;t grow unbounded.
    
    Reported-by: Adam Williamson &lt;awilliam@redhat.com&gt;
    Reported-by: Dusty Mabe &lt;dustymabe@redhat.com&gt;
    Reviewed-by: Richard Guy Briggs &lt;rgb@redhat.com&gt;
    Signed-off-by: Paul Moore &lt;paul@paul-moore.com&gt;</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10513645</commentid>
    <comment_count>42</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-16 11:58:53 -0400</bug_when>
    <thetext>A link to the commit from comment #41 in the audit/next repo in case we want to backport this to Fedora before it gets picked up in 4.13.

http://git.infradead.org/users/pcmoore/audit/commit/c81be52a3ac0267aa830a2c4cb769030ea3483c9</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10513756</commentid>
    <comment_count>43</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-16 12:30:52 -0400</bug_when>
    <thetext>Notified the Fedora Kernel list about the bug and the fix:

https://lists.fedoraproject.org/archives/list/kernel@lists.fedoraproject.org/thread/FGSKQW5KEYTELI33ELRAD43RXDV62ECR

I&apos;m going to go ahead and put this BZ in POST as I&apos;m not sure there is much more for me to do with this BZ from a Fedora perspective.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10513839</commentid>
    <comment_count>44</comment_count>
    <who name="Paul Moore">pmoore</who>
    <bug_when>2017-06-16 13:05:05 -0400</bug_when>
    <thetext>From Laura Abbott:

&gt; Given it was important enough to file a bugzilla, I went ahead and
&gt; applied it to F24/F25/F26 since it went cleanly. It should show up
&gt; in the next kernel version.

See link to mailing list thread in comment #43.

Marking this as CLOSED/NEXTRELEASE.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10520791</commentid>
    <comment_count>45</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-19 19:06:16 -0400</bug_when>
    <thetext>kernel-4.11.6-300.fc26 has been submitted as an update to Fedora 26. https://bodhi.fedoraproject.org/updates/FEDORA-2017-1225995344</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10520799</commentid>
    <comment_count>46</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-19 19:08:05 -0400</bug_when>
    <thetext>kernel-4.11.6-200.fc25 has been submitted as an update to Fedora 25. https://bodhi.fedoraproject.org/updates/FEDORA-2017-b93e6de389</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10520807</commentid>
    <comment_count>47</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-19 19:10:23 -0400</bug_when>
    <thetext>kernel-4.11.6-100.fc24 has been submitted as an update to Fedora 24. https://bodhi.fedoraproject.org/updates/FEDORA-2017-79f099cbba</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10521290</commentid>
    <comment_count>48</comment_count>
    <who name="David H. Gutteridge">dhgutteridge</who>
    <bug_when>2017-06-19 23:00:19 -0400</bug_when>
    <thetext>(In reply to Dusty Mabe from comment #32)
&gt; Never really paid any attention to this before, but I think I notice this
&gt; same problem on my Fedora 25 desktop at home. I switched to a different tty
&gt; (to get to a login prompt) and I notice audit messages there. auditd is
&gt; running.
&gt; 
&gt; This might be an interesting data point.

FWIW, I reported this as https://bugzilla.redhat.com/show_bug.cgi?id=1449831, but didn&apos;t have success reproducing it on demand.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10524208</commentid>
    <comment_count>49</comment_count>
    <who name="Adam Williamson">awilliam</who>
    <bug_when>2017-06-20 13:03:23 -0400</bug_when>
    <thetext>Thanks a lot, Paul and Laura!</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10525739</commentid>
    <comment_count>50</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-21 00:28:19 -0400</bug_when>
    <thetext>kernel-4.11.6-200.fc25 has been pushed to the Fedora 25 testing repository. If problems still persist, please make note of it in this bug report.
See https://fedoraproject.org/wiki/QA:Updates_Testing for
instructions on how to install test updates.
You can provide feedback for this update here: https://bodhi.fedoraproject.org/updates/FEDORA-2017-b93e6de389</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10525926</commentid>
    <comment_count>51</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-21 02:22:49 -0400</bug_when>
    <thetext>kernel-4.11.6-300.fc26 has been pushed to the Fedora 26 testing repository. If problems still persist, please make note of it in this bug report.
See https://fedoraproject.org/wiki/QA:Updates_Testing for
instructions on how to install test updates.
You can provide feedback for this update here: https://bodhi.fedoraproject.org/updates/FEDORA-2017-1225995344</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10527905</commentid>
    <comment_count>52</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-21 10:01:05 -0400</bug_when>
    <thetext>kernel-4.11.6-301.fc26 has been submitted as an update to Fedora 26. https://bodhi.fedoraproject.org/updates/FEDORA-2017-d3ed702fe4</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10527930</commentid>
    <comment_count>53</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-21 10:03:38 -0400</bug_when>
    <thetext>kernel-4.11.6-201.fc25 has been submitted as an update to Fedora 25. https://bodhi.fedoraproject.org/updates/FEDORA-2017-d7bc1b3056</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10527947</commentid>
    <comment_count>54</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-21 10:05:34 -0400</bug_when>
    <thetext>kernel-4.11.6-101.fc24 has been submitted as an update to Fedora 24. https://bodhi.fedoraproject.org/updates/FEDORA-2017-05f10e29f4</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10533588</commentid>
    <comment_count>55</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-22 23:25:09 -0400</bug_when>
    <thetext>kernel-4.11.6-101.fc24 has been pushed to the Fedora 24 testing repository. If problems still persist, please make note of it in this bug report.
See https://fedoraproject.org/wiki/QA:Updates_Testing for
instructions on how to install test updates.
You can provide feedback for this update here: https://bodhi.fedoraproject.org/updates/FEDORA-2017-05f10e29f4</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10533633</commentid>
    <comment_count>56</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-22 23:27:18 -0400</bug_when>
    <thetext>kernel-4.11.6-201.fc25 has been pushed to the Fedora 25 testing repository. If problems still persist, please make note of it in this bug report.
See https://fedoraproject.org/wiki/QA:Updates_Testing for
instructions on how to install test updates.
You can provide feedback for this update here: https://bodhi.fedoraproject.org/updates/FEDORA-2017-d7bc1b3056</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10533946</commentid>
    <comment_count>57</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-23 02:23:32 -0400</bug_when>
    <thetext>kernel-4.11.6-301.fc26 has been pushed to the Fedora 26 testing repository. If problems still persist, please make note of it in this bug report.
See https://fedoraproject.org/wiki/QA:Updates_Testing for
instructions on how to install test updates.
You can provide feedback for this update here: https://bodhi.fedoraproject.org/updates/FEDORA-2017-d3ed702fe4</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10536509</commentid>
    <comment_count>58</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-23 15:51:08 -0400</bug_when>
    <thetext>kernel-4.11.6-101.fc24 has been pushed to the Fedora 24 stable repository. If problems still persist, please make note of it in this bug report.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10536610</commentid>
    <comment_count>59</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-23 16:52:31 -0400</bug_when>
    <thetext>kernel-4.11.6-201.fc25 has been pushed to the Fedora 25 stable repository. If problems still persist, please make note of it in this bug report.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10536995</commentid>
    <comment_count>60</comment_count>
    <who name="Fedora Update System">updates</who>
    <bug_when>2017-06-23 23:06:21 -0400</bug_when>
    <thetext>kernel-4.11.6-301.fc26 has been pushed to the Fedora 26 stable repository. If problems still persist, please make note of it in this bug report.</thetext>
  </long_desc><long_desc isprivate="0" >
    <commentid>10550831</commentid>
    <comment_count>61</comment_count>
    <who name="Dusty Mabe">dustymabe</who>
    <bug_when>2017-06-28 15:12:14 -0400</bug_when>
    <thetext>i think needinfo is no longer needed</thetext>
  </long_desc>
      
          <attachment
              isobsolete="1"
              ispatch="1"
              isprivate="0"
          >
            <attachid>1287102</attachid>
            <date>2017-06-12 17:17:00 -0400</date>
            <delta_ts>2017-06-13 15:23:04 -0400</delta_ts>
            <desc>01-XXX-audit-reset_fix.patch</desc>
            <filename>01-XXX-audit-reset_fix.patch</filename>
            <type>text/plain</type>
            <size>5088</size>
            <attacher name="Paul Moore">pmoore</attacher>
            
              <data encoding="base64">YXVkaXQ6IGZpeCBhIHJhY2UgY29uZGl0aW9uIHdpdGggdGhlIGF1ZGl0ZCB0cmFja2luZyBjb2Rl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</data>

          </attachment>
          <attachment
              isobsolete="0"
              ispatch="1"
              isprivate="0"
          >
            <attachid>1287438</attachid>
            <date>2017-06-13 15:23:00 -0400</date>
            <delta_ts>2017-06-13 15:23:04 -0400</delta_ts>
            <desc>04-XXX-audit-reset_fix.patch</desc>
            <filename>04-XXX-audit-reset_fix.patch</filename>
            <type>text/plain</type>
            <size>5157</size>
            <attacher name="Paul Moore">pmoore</attacher>
            
              <data encoding="base64">YXVkaXQ6IGZpeCBhIHJhY2UgY29uZGl0aW9uIHdpdGggdGhlIGF1ZGl0ZCB0cmFja2luZyBjb2Rl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</data>

          </attachment>
      

    </bug>

</bugzilla>